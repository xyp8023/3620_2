{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing of data\n",
    "# Function to load data\n",
    "\n",
    "def get_power_data():\n",
    "    \"\"\"\n",
    "    Read the Individual household electric power consumption dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    # Assume that the dataset is located on folder \"data\"\n",
    "    data = pd.read_csv('data/household_power_consumption.txt',\n",
    "                       sep=';', low_memory=False)\n",
    "\n",
    "    # Drop some non-predictive variables\n",
    "    data = data.drop(columns=['Date', 'Time'], axis=1)\n",
    "\n",
    "    #print(data.head())\n",
    "\n",
    "    # Replace missing values\n",
    "    data = data.replace('?', np.nan)\n",
    "\n",
    "    # Drop NA\n",
    "    data = data.dropna(axis=0)\n",
    "\n",
    "    # Normalize\n",
    "    standard_scaler = preprocessing.StandardScaler()\n",
    "    np_scaled = standard_scaler.fit_transform(data)\n",
    "    data = pd.DataFrame(np_scaled)\n",
    "\n",
    "    # Goal variable assumed to be the first\n",
    "    X = data.values[:, 1:].astype('float32')\n",
    "    y = data.values[:, 0].astype('float32')\n",
    "\n",
    "    # Create categorical y for binary classification with balanced classes\n",
    "    y = np.sign(y+0.46)\n",
    "\n",
    "    # Split train and test data here: (X_train, Y_train, X_test, Y_test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    no_class = 2                 #binary classification\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, no_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "X,y types: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\nX size (1536960, 6)\nY size (1536960,)\n"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, no_class = get_power_data()\n",
    "print(\"X,y types: {} {}\".format(type(X_train), type(y_train)))\n",
    "print(\"X size {}\".format(X_train.shape))\n",
    "print(\"Y size {}\".format(y_train.shape))\n",
    "\n",
    "# Create a binary variable from one of the columns.\n",
    "# You can use this OR not\n",
    "\n",
    "idx = y_train >= 0\n",
    "notidx = y_train < 0\n",
    "y_train[idx] = 1\n",
    "y_train[notidx] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(x, derivative=False):\n",
    "    sigm = 1. / (1. + np.exp(-x)) \n",
    "    if derivative:\n",
    "        return sigm * (1. - sigm)\n",
    "    return sigm\n",
    "\n",
    "# Define weights initialization\n",
    "def initialize_w(N, d):\n",
    "    return 2*np.random.random((N,d)) - 1\n",
    "\n",
    "# Fill in feed forward propagation\n",
    "def feed_forward_propagation(X, y, w_1, w_2, w_3, lmbda):\n",
    "    # Fill in\n",
    "    # X (N,d)\n",
    "    # w_1 (d,h)\n",
    "    # w_2 (h,h)\n",
    "    # w_3 (h,1)\n",
    "    layer_0 = X\n",
    "    layer_1 = sigmoid(np.dot(X, w_1)) # (N,h)\n",
    "    layer_2 = sigmoid(np.dot(layer_1, w_2)) # (N,h)\n",
    "    layer_3 = np.dot(layer_2, w_3) # (N,1)\n",
    "\n",
    "    # np.linalg.norm(np.dot(np.dot(sigmoid(np.dot(X, w_1)),w_2),w_3) - y.reshape((-1,1)))**2/X.shape[0]\n",
    "    \n",
    "    return layer_0, layer_1, layer_2, layer_3\n",
    "    \n",
    "# Fill in backpropagation    \n",
    "def back_propagation(y, w_1, w_2, w_3, layer_0, layer_1, layer_2, layer_3):\n",
    "    y = y.reshape((-1,1))\n",
    "    N = layer_0.shape[0]\n",
    "    # Calculate the gradient here\n",
    "    # print(\"w_1 shape: \",w_1.shape)\n",
    "    # print(\"layer_0 shape: \",layer_0.shape)\n",
    "    dl_dl3 = 2 * (layer_3-y) # (N,1)\n",
    "    dl3_dw3 = layer_2 # (N, h)\n",
    "    dl3_dl2 = w_3 # (h,1)\n",
    "    dl2_dw2 = -sigmoid(np.dot(layer_1, w_2), derivative=True) * layer_1 # (N,h)\n",
    "    # print(\"dl2_dw2.shape: \", dl2_dw2.shape)\n",
    "\n",
    "    dl2_dl1 = -np.dot(sigmoid(np.dot(layer_1, w_2), derivative=True), w_2) # (N,h)\n",
    "    # print(\"dl2_dl1.shape: \", dl2_dl1.shape)\n",
    "    \n",
    "    # (N,h) (N,d)\n",
    "    dl1_dw1 = -np.dot(sigmoid(np.dot(layer_0, w_1), derivative=True).T, layer_0) # (h,d)\n",
    "    # print(\"dl1_dw1.shape: \", dl1_dw1.shape)\n",
    "\n",
    "    # TODO\n",
    "    # gradient w.r.t w_3 # (h,1)\n",
    "    layer_3_delta = np.dot(dl3_dw3.T, dl_dl3)/N\n",
    "\n",
    "    # gradient w.r.t w_2 # (h,h)\n",
    "    layer_2_delta = np.dot(np.dot(dl3_dl2,dl_dl3.T), dl2_dw2)/N\n",
    "\n",
    "    # gradient w.r.t w_1\n",
    "\n",
    "    # (d,h) = (N,1) (h,1) (N,h) (h,d)\n",
    "    # layer_1_delta = dl_dl3 * dl3_dl2 * dl2_dl1 *dl1_dw1\n",
    "    layer_1_delta = np.dot(dl1_dw1.T, np.dot(dl2_dl1.T, np.dot(dl_dl3, dl3_dl2.T)))/N\n",
    "    return layer_1_delta, layer_2_delta, layer_3_delta\n",
    "\n",
    "# Cost function\n",
    "def cost(X, y, w_1, w_2, w_3, lmbda):\n",
    "    N, d = X.shape\n",
    "    a1,a2,a3,a4 = feed_forward_propagation(X,y,w_1,w_2,w_3,lmbda)\n",
    "\n",
    "    return np.linalg.norm(a4[:,0] - y,2) ** 2 / N\n",
    "\n",
    "# Define SGD\n",
    "def SGD(X, y, w_1, w_2, w_3, lmbda, learning_rate, batch_size):\n",
    "    # Complete here:\n",
    "    y = y.reshape((-1,1))\n",
    "    randomInd = np.arange(X.shape[0])[:batch_size]\n",
    "    layer_0, layer_1, layer_2, layer_3 = feed_forward_propagation(X[randomInd,:],y[randomInd,:],w_1,w_2,w_3,lmbda)\n",
    "    layer_1_delta, layer_2_delta, layer_3_delta = back_propagation(y[randomInd,:], w_1, w_2, w_3, layer_0, layer_1, layer_2, layer_3)\n",
    "    w_1 = w_1 - learning_rate*layer_1_delta\n",
    "    w_2 = w_2 - learning_rate*layer_2_delta\n",
    "    w_3 = w_3 - learning_rate*layer_3_delta\n",
    "\n",
    "    return w_1, w_2, w_3\n",
    "\n",
    "# Define SVRG here:\n",
    "def SVRG(X, y, w_1, w_2, w_3, lmbda, learning_rate, T):\n",
    "    # Complete here:\n",
    "    \n",
    "    return w_1, w_2, w_3\n",
    "\n",
    "# Define GD here:\n",
    "def GD(X, y, w_1,w_2,w_3, learning_rate, lmbda, iterations):\n",
    "    # Complete here:\n",
    "    \n",
    "    return w_1, w_2, w_3\n",
    "\n",
    "# Define projected GD here:\n",
    "def PGD(X, y, w_1,w_2,w_3, learning_rate, lmbda, iterations, noise):\n",
    "    # Complete here:\n",
    "    \n",
    "    return w_1, w_2, w_3\n",
    "\n",
    "# Define BCD here:\n",
    "def BCD(X, y, w_1,w_2,w_3, learning_rate, lmbda, iterations):\n",
    "    # Complete here:\n",
    "    \n",
    "    return w_1, w_2, w_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(512320, 6)\n(512320, 10)\n(512320, 10)\n(512320, 1)\nlayer_3_delta shape (10, 1)\nlayer_2_delta shape (10, 10)\nlayer_1_delta shape (6, 10)\n"
    }
   ],
   "source": [
    "w_size = 10\n",
    "\n",
    "# Initialize weights\n",
    "w_1 = initialize_w(X_train.shape[1], w_size)\n",
    "\n",
    "w_2 = initialize_w(w_size,w_size)\n",
    "\n",
    "w_3 = initialize_w(w_size, 1)\n",
    "\n",
    "lmbda = 0\n",
    "\n",
    "layer_0, layer_1, layer_2, layer_3 = feed_forward_propagation(X_test, y_test, w_1, w_2, w_3, lmbda)\n",
    "\n",
    "print(layer_0.shape)\n",
    "print(layer_1.shape)\n",
    "print(layer_2.shape)\n",
    "print(layer_3.shape)\n",
    "\n",
    "layer_1_delta, layer_2_delta, layer_3_delta = back_propagation(y_test, w_1, w_2, w_3, layer_0, layer_1, layer_2, layer_3)\n",
    "# print(layer_1_delta.shape)\n",
    "print(\"layer_3_delta shape\", layer_3_delta.shape)\n",
    "print(\"layer_2_delta shape\", layer_2_delta.shape)\n",
    "print(\"layer_1_delta shape\", layer_1_delta.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0 2.0253811878426884\n10 1.3009922199895438\n20 1.0571819456529723\n30 0.9568117948206131\n40 0.9078194732941943\n50 0.8796932724194646\n60 0.8608691618272107\n70 0.8464471397705512\n80 0.8341741568018064\n90 0.8229565761698402\n100 0.8122442341943406\n110 0.8017530160008748\n120 0.7913331200173264\n130 0.7809048279676775\n140 0.7704269932524067\n150 0.7598817082085588\n160 0.7492669202887466\n170 0.738592770516539\n180 0.7278794504933694\n190 0.7171554546873361\n200 0.7064557256585191\n210 0.695819579361697\n220 0.6852885416222048\n230 0.6749043273250684\n240 0.664707153304347\n250 0.6547344601397892\n260 0.6450200222728435\n270 0.6355933881227739\n280 0.6264795816835388\n290 0.6176989976883092\n300 0.6092674408211928\n310 0.6011962837116802\n320 0.593492735216909\n330 0.58616021611668\n340 0.5791988328587723\n350 0.5726059251388749\n360 0.5663766479283086\n370 0.5605045400154939\n380 0.5549820320555238\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-7821dfb63e75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mw_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-cc5a795bd324>\u001b[0m in \u001b[0;36mcost\u001b[0;34m(X, y, w_1, w_2, w_3, lmbda)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_forward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-cc5a795bd324>\u001b[0m in \u001b[0;36mfeed_forward_propagation\u001b[0;34m(X, y, w_1, w_2, w_3, lmbda)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# w_3 (h,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mlayer_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mlayer_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (N,h)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mlayer_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (N,h)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mlayer_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (N,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-cc5a795bd324>\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(x, derivative)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Sigmoid function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderivative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msigm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mderivative\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msigm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msigm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Should be a hyperparameter that you tune, not an argument - Fill in the values\n",
    "lmbda =0.\n",
    "w_size = 10\n",
    "lr = 0.01\n",
    "iterations = 1000\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "# Initialize weights\n",
    "w_1 = initialize_w(X_train.shape[1], w_size)\n",
    "\n",
    "w_2 = initialize_w(w_size,w_size)\n",
    "\n",
    "w_3 = initialize_w(w_size, 1)\n",
    "for i in range(iterations):\n",
    "    w_1,w_2,w_3 = SGD(X_train, y_train, w_1, w_2, w_3, lmbda, lr, batch_size)\n",
    "    loss = cost(X_train, y_train, w_1, w_2, w_3, lmbda)\n",
    "    if i%10==0:\n",
    "        print(i,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be a hyperparameter that you tune, not an argument - Fill in the values\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--lambda', type=float, default=0., dest='lmbda') \n",
    "parser.add_argument('--w_size', type=int, default=10, dest='w_size')\n",
    "parser.add_argument('--lr', type=float, default=0.01)\n",
    "parser.add_argument('--iterations', type=int, default=10)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "# Initialize weights\n",
    "w_1 = initialize_w(X_train.shape[1], args.w_size)\n",
    "\n",
    "w_2 = initialize_w(args.w_size,args.w_size)\n",
    "\n",
    "w_3 = initialize_w(args.w_size, 1)\n",
    "\n",
    "# Get iterations\n",
    "iterations = args.iterations\n",
    "# Define plotting variables\n",
    "fig, ax = plt.subplots(2, 1, figsize=(16, 8))\n",
    "\n",
    "# Define the optimizers for the loop\n",
    "optimizers = [\n",
    "        {# Fill in the hyperparameters\n",
    "            \"opt\": SGD(X_train, y_train, w_1, w_2, w_3, args.lmbda, args.lr, batch_size),\n",
    "            \"name\": \"SGD\",\n",
    "            \"inner\": # Fill in\n",
    "        },\n",
    "        {# Fill in the hyperparameters\n",
    "            \"opt\": SVRG(X_train, y_train, w_1, w_2, w_3, args.lmbda, args.lr),\n",
    "            \"name\": \"SVRG\",\n",
    "            \"inner\": # Fill in\n",
    "        },\n",
    "        {# Fill in the hyperparameters\n",
    "            \"opt\": GD(\n",
    "                X_train, y_train, w_1, w_2, w_3, learning_rate=args.lr,\n",
    "                lmbda=args.lmbda, iterations=iterations),\n",
    "            \"name\": \"GD\",\n",
    "            \"inner\": # Fill in\n",
    "        },\n",
    "        {# Fill in the hyperparameters\n",
    "            \"opt\": PGD(\n",
    "                X_train, y_train, w_1, w_2, w_3, learning_rate=args.lr,\n",
    "                lmbda=args.lmbda, iterations=iterations, noise=),\n",
    "            \"name\": \"PGD\",\n",
    "            \"inner\": # Fill in\n",
    "        },\n",
    "        {# Fill in the hyperparameters\n",
    "            \"opt\": BCD(\n",
    "                X_train, y_train, w_1, w_2, w_3, learning_rate=args.lr,\n",
    "                lmbda=args.lmbda, iterations=iterations),\n",
    "            \"name\": \"BCD\",\n",
    "            \"inner\": # Fill in\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the iterates over the algorithms above\n",
    "\n",
    "for opt in optimizers:\n",
    "    #\n",
    "    # Fill in\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "ax[0].legend(loc=\"upper right\")\n",
    "ax[0].set_xlabel(r\"Iteration\", fontsize=16)\n",
    "ax[0].set_ylabel(\"Loss\", fontsize=16)\n",
    "ax[0].set_title(\"CA3 - Training a deep neural network for the power consumption Dataset\")\n",
    "ax[0].set_ylim(ymin=0)\n",
    "\n",
    "ax[1].legend(loc=\"upper right\")\n",
    "ax[1].set_xlabel(r\"Time [s]\", fontsize=16)\n",
    "ax[1].set_ylabel(\"Loss\", fontsize=16)\n",
    "ax[1].set_ylim(ymin=0)\n",
    "\n",
    "plt.savefig(\"power.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('sklearn': conda)",
   "language": "python",
   "name": "python38164bitsklearnconda11bdb1c82f4e41ea847f64346c43e799"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}